# Transforma√ß√£o de Dados com Pentaho Data Integration

Este reposit√≥rio serve como um guia pr√°tico e demonstrativo sobre o processo de **Extra√ß√£o, Transforma√ß√£o e Carga (ETL)** utilizando a ferramenta open-source **Pentaho Data Integration (PDI)**. O objetivo √© ilustrar um fluxo de trabalho completo, desde a coleta de dados brutos de m√∫ltiplas fontes at√© a sua consolida√ß√£o em um **Data Warehouse (DW)**, preparando-os para an√°lise e gera√ß√£o de insights.

---
## O Conceito de ETL

ETL √© um processo fundamental em Business Intelligence e engenharia de dados. Ele consiste em tr√™s etapas distintas:

1.  **Extra√ß√£o (Extract):** A primeira fase envolve a coleta de dados de diversas fontes, que podem ser bancos de dados relacionais (MySQL, PostgreSQL), arquivos de texto (CSV, JSON, XML), planilhas ou APIs de servi√ßos web.

2.  **Transforma√ß√£o (Transform):** Esta √© a etapa mais complexa, onde os dados extra√≠dos s√£o convertidos para um formato adequado. As tarefas de transforma√ß√£o incluem:
    * **Limpeza:** Corre√ß√£o de inconsist√™ncias, erros e tratamento de valores nulos.
    * **Padroniza√ß√£o:** Aplica√ß√£o de regras para uniformizar os dados (ex: formatos de data, unidades de medida).
    * **Enriquecimento:** Cruzamento de dados com outras fontes para adicionar novas informa√ß√µes.
    * **Agrega√ß√£o:** Sumariza√ß√£o dos dados (ex: total de vendas por regi√£o).

3.  **Carga (Load):** Na fase final, os dados j√° transformados s√£o carregados no destino final, que geralmente √© um Data Warehouse ou um Data Mart, onde estar√£o dispon√≠veis para consulta e an√°lise.

A imagem abaixo ilustra de forma simplificada este fluxo:

![Ilustra√ß√£o do processo ETL](https://imgur.com/a/HLKf7uF)
*Fonte: Diagrama gen√©rico do processo ETL.*

---
## O que √© um Data Warehouse?

Um **Data Warehouse (DW)** √© um reposit√≥rio centralizado e otimizado para an√°lise de dados. Diferente de um banco de dados transacional (OLTP), que √© projetado para registrar transa√ß√µes do dia a dia, um DW √© projetado para consultas anal√≠ticas complexas (OLAP).

Ele armazena dados hist√≥ricos e atuais de forma consolidada, provenientes de diferentes sistemas da organiza√ß√£o, servindo como uma **"fonte √∫nica da verdade"** para suportar a tomada de decis√µes estrat√©gicas.

A arquitetura t√≠pica de um Data Warehouse √© demonstrada abaixo:

![Arquitetura de um Data Warehouse](https://imgur.com/TFfSwXR)
*Fonte: Diagrama gen√©rico da arquitetura de um Data Warehouse.*

---
## üõ†Ô∏è Ferramentas e Tecnologias

* **Pentaho Data Integration (PDI / Kettle):** Ferramenta principal para o desenvolvimento visual dos fluxos de ETL.
* **MySQL / PostgreSQL:** Exemplos de Sistemas Gerenciadores de Banco de Dados que podem ser usados como fonte (origem) e destino (DW).
* **Spoon:** A interface gr√°fica do PDI onde as transforma√ß√µes (`.ktr`) e os jobs (`.kjb`) s√£o criados.

---
## üöÄ Como Executar o Projeto

Para executar os exemplos contidos neste reposit√≥rio, siga os passos abaixo:

1.  **Instala√ß√£o:** Certifique-se de ter o [Pentaho Data Integration (Community Edition)](https://www.hitachivantara.com/en-us/products/pentaho-platform/data-integration-analytics/pentaho-community-edition.html) instalado.
2.  **Banco de Dados:** Prepare seu banco de dados de origem e destino. Os scripts para cria√ß√£o das tabelas de exemplo est√£o na pasta `/scripts_sql`.
3.  **Configura√ß√£o:** Abra os arquivos de transforma√ß√£o (`.ktr`) ou job (`.kjb`) no Spoon. Acesse a √°rea de "View" e configure as conex√µes de banco de dados para apontar para o seu ambiente.
4.  **Execu√ß√£o:** Com as conex√µes configuradas, clique no bot√£o "Play" (Executar) na interface do Spoon para iniciar o processo.

---
## üìÇ Estrutura do Reposit√≥rio